import codecademylib3_seaborn
from sklearn.linear_model import Perceptron
import matplotlib.pyplot as plt
import numpy as np
from itertools import product

data = [
  [0,0], [0,1], [1,0], [1,1]
]

labels = [0, 0, 0, 1]

#lets change the labels so the data now represents an XOR gate
labels1=[0, 1, 1, 0]

#OR gate
labels2=[0, 1, 1, 1]

x = [point[0] for point in data]
y = [point[1] for point in data]

plt.scatter(x,y,c=labels)
plt.show()

#lets build a perceptron to learn operator AND:

#number of times the perceptron loops through the training data (the default is 1000):
'''max_iter=40 - we are cutting the training pretty short'''

classifier = Perceptron(max_iter=40)

classifier.fit(data,labels2)

print(classifier.score(data,labels2))
#the accuracy is 100% for AND and OR gates and only 50% for XOR gates

#given a list of points, this method returns the distance those points are from the decision boundary
print(classifier.decision_function([[0,0],[1,1],[0.5,0.5]]))

print(classifier.decision_function([[0,0.1],[0,0.2]]))

#make a heat map that reveals the decision boundary
#list of 100 evenly spaced decimals between 0 and 1
x_values = np.linspace(0,1,100)
y_values = np.linspace(0,1,100)

point_grid = list(product(x_values,y_values))

distances = classifier.decision_function(point_grid)

abs_distances = abs(distances)

distances_matrix = np.reshape(abs_distances,(100,100))

#draw heat map
heatmap = plt.pcolormesh(x_values,y_values,distances_matrix)

plt.colorbar(heatmap)
plt.show()

#you should see a purple line where distances are zero. that's decision boundary

#Perceptrons can't solve problems that aren't linearly separable. However if you combine multiple perceptrons together you can have a neural net that can solve these problems

#AND and OR gates cant produce the output of XOR gates but when you combine a few ANDs and ORs you can make an XOR!

